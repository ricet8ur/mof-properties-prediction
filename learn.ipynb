{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import orjson\n",
    "import zipfile\n",
    "import zstandard as zstd\n",
    "import shutil\n",
    "from pymatgen.core import Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From QMOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expecting to have qmof_database.zip (downloaded from Figshare https://docs.materialsproject.org/apps/explorer-apps/mof-explorer/downloading-the-data) inside folder data/qmof_db/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset saving paths\n",
    "basedir = \"data/\"\n",
    "qmof_db_dir = basedir + \"QMOF/\"\n",
    "qmof_db_zip_path = basedir + \"QMOF/qmof_database.zip\"\n",
    "qmof_db_path = qmof_db_dir + \"qmof_database/\"\n",
    "if not Path(qmof_db_dir + \"qmof_database\").is_dir():\n",
    "    with zipfile.ZipFile(qmof_db_zip_path, \"r\") as f:\n",
    "        f.extractall(qmof_db_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(data: dict, output_file):\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(orjson.dumps(data, option=orjson.OPT_SERIALIZE_NUMPY))\n",
    "\n",
    "\n",
    "def load_from_json(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        return orjson.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(from_file, to_file):\n",
    "    with open(from_file, \"rb\") as f:\n",
    "        res = zstd.ZstdCompressor(level=15, threads=-1).compress(f.read())\n",
    "    with open(to_file, \"wb\") as f:\n",
    "        f.write(res)\n",
    "\n",
    "\n",
    "def decompress(from_file, to_file):\n",
    "    with open(from_file, \"rb\") as f:\n",
    "        res = zstd.decompress(f.read())\n",
    "    with open(to_file, \"wb\") as f:\n",
    "        f.write(res)\n",
    "\n",
    "\n",
    "def compress_inplace(dataset_path):\n",
    "    filenames = os.listdir(dataset_path)\n",
    "    for filename in filenames:\n",
    "        if filename == \"props.json\" or filename == \"cifs.json\":\n",
    "            compress(dataset_path + filename, dataset_path + filename + \".zstd\")\n",
    "\n",
    "\n",
    "def decompress_inplace(dataset_path):\n",
    "    filenames = os.listdir(dataset_path)\n",
    "    for filename in filenames:\n",
    "        if filename == \"props.json.zstd\" or filename == \"cifs.json.zstd\":\n",
    "            decompress(\n",
    "                dataset_path + filename, dataset_path + filename.removesuffix(\".zstd\")\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cif_read():\n",
    "    with open(qmof_db_path + \"qmof_structure_data.json\", \"rb\") as f:\n",
    "        struct_data = orjson.loads(f.read())\n",
    "\n",
    "\n",
    "def create_cifs():\n",
    "    with open(qmof_db_path + \"qmof_structure_data.json\", \"rb\") as f:\n",
    "        struct_data = orjson.loads(f.read())\n",
    "    cifs = {}\n",
    "    for entry in struct_data:\n",
    "        cifs[entry[\"qmof_id\"]] = entry[\"structure\"]\n",
    "    with open(basedir + \"cifs.json\", \"wb\") as f:\n",
    "        f.write(orjson.dumps(cifs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_props_from_band_gap():\n",
    "    props = dict()\n",
    "    with open(qmof_db_path + \"qmof.json\", \"rb\") as f:\n",
    "        qmof = orjson.loads(f.read())\n",
    "        # print(qmof[0]['outputs']['pbe']['bandgap'])\n",
    "        for m in qmof:\n",
    "            name = m[\"qmof_id\"]\n",
    "            value = {\"bandgap\": m[\"outputs\"][\"pbe\"][\"bandgap\"]}\n",
    "            props[name] = value\n",
    "    with open(basedir + \"props.json\", \"wb\") as f:\n",
    "        f.write(orjson.dumps(props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_props_from_band_gap()\n",
    "create_cifs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_property_to_ids(\n",
    "    df: pd.DataFrame, property: str, csv: str = \"./data/root/data/id_prop.csv\"\n",
    "):\n",
    "    df[property].dropna().to_csv(csv, index=True, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "is_clearml = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot general train progress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ds_prop_mae = dict()\n",
    "\n",
    "\n",
    "def plot_ds_prop_mae():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for ds, prop_mae in ds_prop_mae.items():\n",
    "        props = list(prop_mae.keys())\n",
    "        maes = list(prop_mae[k] for k in props)\n",
    "        # line\n",
    "        (c,) = plt.plot(props, maes, alpha=0.3, lw=2)\n",
    "        color = c.get_color()\n",
    "        # point\n",
    "        plt.scatter(props, maes, alpha=0.6, color=color, marker=\"x\", s=25)\n",
    "        # label\n",
    "        plt.plot([], [], alpha=1, color=color, label=ds)\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(\"MAE for different datasets and properties\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_default(ds_path: str, **kwargs) -> tuple[float, dict]:\n",
    "    \"\"\"train with default hyperparameters\"\"\"\n",
    "    import model.main as main\n",
    "\n",
    "    main.args.use_clearml = True\n",
    "    main.args.max_cache_size = 160000\n",
    "    main.args.data_options = [ds_path]\n",
    "    mae = main.main()\n",
    "\n",
    "    return float(mae), vars(main.args).copy()\n",
    "\n",
    "\n",
    "def clearml_train_logger(\n",
    "    ds_path: str,\n",
    "    property: str,\n",
    "    train_fn: Callable[[str], float],\n",
    "    notes: str = \"\",\n",
    "):\n",
    "    ds_name = Path(ds_path).name\n",
    "    if not is_clearml:\n",
    "        mae = train_fn()\n",
    "        print(ds_name, mae)\n",
    "    else:\n",
    "        # prepare task\n",
    "        from clearml import Task\n",
    "\n",
    "        Task.set_offline(True)\n",
    "\n",
    "        task: Task = Task.init(\n",
    "            project_name=\"rcgcnn\",\n",
    "            task_name=f\"train {property} on {ds_name}\",\n",
    "            auto_connect_frameworks={\n",
    "                # gpu info\n",
    "                \"tensorboard\": True,\n",
    "                \"matplotlib\": True,\n",
    "                \"tensorflow\": False,\n",
    "                \"pytorch\": True,\n",
    "                \"xgboost\": False,\n",
    "                \"scikit\": False,\n",
    "                \"fastai\": False,\n",
    "                \"lightgbm\": False,\n",
    "                \"hydra\": False,\n",
    "                \"detect_repository\": False,\n",
    "                \"tfdefines\": False,\n",
    "                \"joblib\": False,\n",
    "                \"megengine\": False,\n",
    "                \"catboost\": False,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        mae, args_dict = train_fn(ds_path, property=property)\n",
    "        # finish task\n",
    "        compress(ds_path + \"id_prop.csv\", ds_path + \"id_prop.csv.zstd\")\n",
    "        task.upload_artifact(\n",
    "            name=\"id_prop.csv.zstd\", artifact_object=ds_path + \"id_prop.csv.zstd\"\n",
    "        )\n",
    "        # save model file\n",
    "        task.upload_artifact(\n",
    "            name=\"model_best.pth.tar\", artifact_object=\"./model_best.pth.tar\"\n",
    "        )\n",
    "        # save test results\n",
    "        compress(\"./test_results.csv\", \"./test_results.csv.zstd\")\n",
    "        task.upload_artifact(\n",
    "            name=\"test_results.csv.zstd\", artifact_object=\"./test_results.csv.zstd\"\n",
    "        )\n",
    "\n",
    "        ds_prop_mae.setdefault(ds_name, dict())[property] = mae\n",
    "\n",
    "        task.upload_artifact(name=\"general_ds_prop_mae\", artifact_object=ds_prop_mae)\n",
    "        task.upload_artifact(name=\"args\", artifact_object=args_dict)\n",
    "\n",
    "        args_info = {\n",
    "            \"args\": args_dict,\n",
    "        }\n",
    "        train_info = {\n",
    "            \"result_mae\": float(mae),\n",
    "            \"ds_path\": ds_path,\n",
    "            \"ds_name\": ds_name,\n",
    "            \"property\": property,\n",
    "            \"notes\": notes,\n",
    "        }\n",
    "        task.connect(args_info)\n",
    "        task.connect(train_info, name=\"train_info\")\n",
    "\n",
    "        if len(notes) > 0:\n",
    "            # rename task taking notes into account\n",
    "            task.set_name(f\"train {property} on {ds_name} {notes}\")\n",
    "\n",
    "        # general progress plot\n",
    "        logger = task.get_logger()\n",
    "        plot_ds_prop_mae()\n",
    "        logger.report_matplotlib_figure(\n",
    "            title=\"General progress plot\",\n",
    "            series=\"MAE\",\n",
    "            figure=plt,\n",
    "            report_interactive=False,\n",
    "            report_image=True,\n",
    "        )\n",
    "        logger.report_matplotlib_figure(\n",
    "            title=\"General progress plot\",\n",
    "            series=\"MAE\",\n",
    "            figure=plt,\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "        task.close()\n",
    "        #\n",
    "        # upload offline task according to https://clear.ml/docs/latest/docs/guides/set_offline/\n",
    "        # Task.set_offline(False)\n",
    "        # Task.import_offline_session(str(task.get_offline_mode_folder()))\n",
    "\n",
    "\n",
    "def train_on_dataset(\n",
    "    ds_path: str,\n",
    "    ds_props: list | dict,\n",
    "    clearml_train_logger: Callable[[str, Callable[[str], float]], float],\n",
    "    train_fn: Callable[[], float],\n",
    "):\n",
    "    print(ds_path, ds_props)\n",
    "    full_df = pd.DataFrame(load_from_json(ds_path + \"props.json\")).transpose()\n",
    "    # clear sys argv for argparse\n",
    "    import sys\n",
    "\n",
    "    sys.argv = [ds_path, ds_path]\n",
    "    del sys\n",
    "    # initialize features from cifs\n",
    "    # args influence CIFData only via data_options, max_cache_size and workers\n",
    "\n",
    "    # shut.copy(basedir + \"atom_init.json\", ds_path)\n",
    "    # choose ds prop format:\n",
    "    for prop in ds_props:\n",
    "        if prop in full_df.columns.values:\n",
    "            set_property_to_ids(full_df, prop, ds_path + \"id_prop.csv\")\n",
    "            clearml_train_logger(ds_path, prop, train_fn)\n",
    "        else:\n",
    "            print(\"no\", prop, \"in\", ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/ ['bandgap']\n",
      "ClearML Task: created new task id=offline-a19c5196f6224306bec08b496309aee5\n",
      "ClearML running in offline mode, session stored in /home/nodoteve/.clearml/cache/offline/offline-a19c5196f6224306bec08b496309aee5\n"
     ]
    }
   ],
   "source": [
    "train_on_dataset(\"./data/\", [\"bandgap\"], clearml_train_logger, train_default)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1509f755d693feea69328e7bc671a76db594dddf9693d82a53ea384d1f791343"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
